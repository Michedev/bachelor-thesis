\chapter{Miglioramenti e conclusioni}
\section{Miglioramenti}
Adesso vediamo i possibili miglioramenti da attuare in tutti i vari aspetti trattati fin'ora, dalla raccolta dati all'accuratezza delle predizioni fino all'applicativo \textit{Android}.
\subsection{Miglioramenti durante la raccolta dati}
\begin{itemize}
	\item L'architettura \textit{client-server} \`e necessaria per avere un'applicazione che riesca a gestire con fluidit\`a la ricerca all'interno di grandi edifici. Il telefono non ha sufficienti risorse perch\`e possiede un quantitativo di \textit{RAM} e memoria permanente molto limitati rispetto alle necessit\`a dei \textit{big data}, ma anche la potenza di calcolo del processore non \`e sufficiente. Per fare un esempio, nella fase ricerca di posizione assumendo l'uso del \textit{KNN}, il modello ha bisogno di confrontare gli attributi delle nuove onde magnetiche con tutti gli altri raccolti fino a quel momento e va da se che pi\`u  \`e grande il \textit{dataset}, pi\`u  potenza di calcolo \`e necessaria per ottenere una risposta in tempi umani.
	\item Durante la raccolta sarebbe opportuno applicare il \textit{filtro di Kalman} per ridurre il rumore causato dall'imprecisione dei sensori. \`E stata usata in fase di test ma non nel codice che gira su dispositivi \textit{mobile}.
	\item Per migliorare la precisione sarebbe opportuno appoggiarsi anche ad altri sensori presenti sullo \textit{smartphone}. Prendiamo come esempio il Wi-Fi, se il dispositivo \`e connesso alla rete dell'edificio potrebbe sfruttare la potenza di segnale per avere un'indicazione pi\`u precisa sulla posizione; sfruttare l'accelerometro per stimare la velocit\`a del telefono. Questa tecnica viene chiamata \textit{sensor fusion}\cite{shala2011indoor}.
	\item Sperimentare nuove tecniche di estrazione e selezione di attributi, fra cui algoritmi genetici, trasformata di \textit{fourier}.
\end{itemize}
\subsection{Miglioramenti per aumentare l'accuratezza durante la ricerca della posizione}
\begin{itemize}
	\item Valutare anche le prestazioni di altri classificatori pi\`u avanzati come \textit{SVM}, reti neurali multistrato.
	\item Invece di valutare solamente la predizione di un singolo classificatore, usarne pi\`u di uno e prendere come etichetta la scelta popolare. Questa tecnica viene chiamata \textit{ensemble learning} di cui un famoso modello \`e la \textit{random forest}.
\end{itemize}
\subsection{Miglioramenti dell'applicazione}
\begin{itemize}
	\item Realizzare un'interfaccia grafica \textit{user friendly}.
	\item In particolare, nell'interfaccia mostrare una mappa $2D$ dell'edificio visitato. Ci\`o si ricollega ad uno dei miglioramenti durante la raccolta dati, perch\`e per mostrare la posizione sono necessari altri sensori.
	\item Trovare i migliori parametri riguardanti la grandezza della \textit{fingerprint} intesa come numero di onde magnetiche di cui \`e composta, quante onde magnetiche raccogliere ogni secondo.
\end{itemize}
\section{Conclusioni}
In conclusione abbiamo una base di applicazione \textit{Android} che, tramite l'uso del \textit{machine learning}, una branca dell'IA, riesce ad azzeccare con un discreto grado di accuratezza la posizione dell'utente all'interno dell'edificio tramite la distorsione del campo magnetico terrestre causata dagli oggetti presenti all'interno dell'edificio. Il \textit{machine learning} \`e solo una parte di tutto il lavoro svolto, che possiamo riassumere con la seguente scaletta:
\begin{enumerate}
	\item Raccolta dell'intensit\`a delle onde magnetiche lungo gli assi tramite il magnetometro presente sullo \textit{smartphone}.
	\item Raggruppamento in \textit{fingerprint} di dimensione prefissata.
	\item Serializzazione dei dati per analisi su computer con architettura del processore $X86\_64$.
	\item \textit{Preprocessing} dei dati, cio\`e  estrazione di caratteristiche di natura statistica. \`E stata evitata la normalizzazione perch\'e \`e stato empiricamente verificato che abbassa l'accuratezza del 20\% circa.
	\item Addestramento del modello, che saltiamo trattandosi del \textit{knn}.
	\item Ricerca della posizione, la quale si traduce nel \textit{machine learning} in classificazione, quindi la predizione di un'etichetta. Nel caso del \textit{knn} si effettua prendendo i primi k elementi che minimizzano la distanza euclidea dagli attributi non ancora classificati, e fra questi l'etichetta quella pi\`u frequente viene assegnata all'istanza non classificata.
\end{enumerate}
Su computer sono stati effettuati test riguardanti il dato che abbiamo trattato, le onde magnetiche tramite l'esposizione di grafici. Abbiamo dimostrato che nei dati \`e presente abbastanza rumore, per poi passare ad un confronto di accuratezza fra i classificatori presenti in cui ha ottenuto un minore errore sull'insieme di test il \textit{knn}. Ma \`e oro tutto ci\`o che luccica? Nella sezione successiva abbiamo visto che l'accuratezza non ci dice tutto, perch\'e il pericolo dell'\textit{overfitting} \`e dietro l'angolo! Abbiamo fatto un esempio col \textit{knn}, dove abbiamo mostrato che con k = 1 si verifica la massima accuratezza anche se sicuramente si tratta di \textit{overfitting}. Uno dei migliori strumenti per evitare di incapparci \`e l'esperienza sul campo, impostando correttamente gli intervalli degli iper-parametri da validare. In alternativa, abbiamo visto che possono aiutarci le curve di validazione per capire se il nostro modello funziona correttamente anche se richiede la definizione di complessit\`a del modello, la scelta della metrica giusta e valutare nel grafico, oltre all'errore sulle predizioni (\textit{bias}), anche all'errore causato dalla varianza che dipende dal modello utilizzato. Ad esempio, sappiamo che col \textit{knn} all'aumentare di k aumenta il \textit{bias} e diminuisce l'errore causato dalla varianza.